{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUMANSH/Data-Science-Projects/blob/main/federated_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Federated Learning Using CIFAR-10 Dataset</b></div>"
      ],
      "metadata": {
        "id": "blgeH6fA60Gb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![_f0b10fc2-0595-441b-8c75-e554671b3088.jpg](attachment:d8d59f78-0929-4986-a7af-187a3bba0382.jpg)"
      ],
      "metadata": {
        "id": "IdukTVsY60Gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Federated Learning (FL) is used to train machine learning models across decentralized devices or data sources without sharing raw data. It is valuable because:\n",
        "\n",
        "Privacy and Security: Keeps data local, preserving user privacy and meeting regulations like GDPR.\n",
        "\n",
        "Decentralization: Enables training across multiple devices or organizations without centralizing data.\n",
        "\n",
        "Efficiency: Reduces data transfer by sharing only model updates, saving bandwidth and resources.\n",
        "\n",
        "Personalization: Creates models tailored to local data while contributing to a global model.\n",
        "\n",
        "Scalability: Scales to thousands of clients, ideal for IoT, edge devices, and large networks.\n",
        "\n",
        "Collaboration: Allows organizations to train models together without sharing sensitive data.\n",
        "\n",
        "FL is used in healthcare, mobile apps, finance, and IoT, offering privacy-preserving, efficient, and collaborative machine learning solutions."
      ],
      "metadata": {
        "id": "MHWW4_cg60Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b>Install Necessary Library </b></div>"
      ],
      "metadata": {
        "id": "aZFxxlAD60Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:05:40.229402Z",
          "iopub.execute_input": "2024-11-25T17:05:40.230374Z",
          "iopub.status.idle": "2024-11-25T17:05:50.498779Z",
          "shell.execute_reply.started": "2024-11-25T17:05:40.230330Z",
          "shell.execute_reply": "2024-11-25T17:05:50.497053Z"
        },
        "_kg_hide-output": true,
        "id": "gPvPp1Q660Ge",
        "outputId": "7fa21b00-b8d2-474e-981f-d5750fbf16da"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: flwr in /opt/conda/lib/python3.10/site-packages (1.13.0)\nRequirement already satisfied: cryptography<43.0.0,>=42.0.4 in /opt/conda/lib/python3.10/site-packages (from flwr) (42.0.8)\nRequirement already satisfied: grpcio!=1.64.2,<2.0.0,<=1.64.3,>=1.60.0 in /opt/conda/lib/python3.10/site-packages (from flwr) (1.62.2)\nRequirement already satisfied: hatchling<2.0.0,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from flwr) (1.26.3)\nRequirement already satisfied: iterators<0.0.3,>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from flwr) (0.0.2)\nRequirement already satisfied: numpy<3.0.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from flwr) (2.1.3)\nRequirement already satisfied: pathspec<0.13.0,>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from flwr) (0.12.1)\nRequirement already satisfied: protobuf<5.0.0,>=4.25.2 in /opt/conda/lib/python3.10/site-packages (from flwr) (4.25.3)\nRequirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from flwr) (3.20.0)\nRequirement already satisfied: rich<14.0.0,>=13.5.0 in /opt/conda/lib/python3.10/site-packages (from flwr) (13.7.1)\nRequirement already satisfied: tomli<3.0.0,>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from flwr) (2.0.1)\nRequirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from flwr) (1.0.0)\nRequirement already satisfied: typer<0.13.0,>=0.12.5 in /opt/conda/lib/python3.10/site-packages (from flwr) (0.12.5)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography<43.0.0,>=42.0.4->flwr) (1.16.0)\nRequirement already satisfied: packaging>=24.2 in /opt/conda/lib/python3.10/site-packages (from hatchling<2.0.0,>=1.25.0->flwr) (24.2)\nRequirement already satisfied: pluggy>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from hatchling<2.0.0,>=1.25.0->flwr) (1.5.0)\nRequirement already satisfied: trove-classifiers in /opt/conda/lib/python3.10/site-packages (from hatchling<2.0.0,>=1.25.0->flwr) (2024.10.21.16)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=13.5.0->flwr) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=13.5.0->flwr) (2.18.0)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<0.13.0,>=0.12.5->flwr) (8.1.7)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from typer<0.13.0,>=0.12.5->flwr) (4.12.0)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<0.13.0,>=0.12.5->flwr) (1.5.4)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr) (2.22)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr) (0.1.2)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Import Libraries and Load CIFAR-10 Dataset</b></div>"
      ],
      "metadata": {
        "id": "IfqWmiZi60Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize images to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test shape: {x_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:05:50.501585Z",
          "iopub.execute_input": "2024-11-25T17:05:50.502736Z",
          "iopub.status.idle": "2024-11-25T17:05:51.503975Z",
          "shell.execute_reply.started": "2024-11-25T17:05:50.502679Z",
          "shell.execute_reply": "2024-11-25T17:05:51.502743Z"
        },
        "id": "vq3sKEpe60Gg",
        "outputId": "aa5ee65a-a415-443f-f98a-72eda429123b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Train shape: (50000, 32, 32, 3), (50000, 10)\nTest shape: (10000, 32, 32, 3), (10000, 10)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Split Data Across Clients</b></div>\n",
        "\n",
        "Simulate data distribution for federated learning by splitting the dataset among clients."
      ],
      "metadata": {
        "id": "TPEXq0VT60Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(x, y, num_clients):\n",
        "    client_data = []\n",
        "    shard_size = len(x) // num_clients\n",
        "    for i in range(num_clients):\n",
        "        start = i * shard_size\n",
        "        end = start + shard_size\n",
        "        client_data.append((x[start:end], y[start:end]))\n",
        "    return client_data\n",
        "\n",
        "# Split data for 3 clients\n",
        "num_clients = 3\n",
        "client_data = split_data(x_train, y_train, num_clients)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:05:51.505582Z",
          "iopub.execute_input": "2024-11-25T17:05:51.505952Z",
          "iopub.status.idle": "2024-11-25T17:05:51.512587Z",
          "shell.execute_reply.started": "2024-11-25T17:05:51.505920Z",
          "shell.execute_reply": "2024-11-25T17:05:51.511315Z"
        },
        "id": "rY6miJCK60Gg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Define the Model</b></div>"
      ],
      "metadata": {
        "id": "YVt39c5h60Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:05:51.514953Z",
          "iopub.execute_input": "2024-11-25T17:05:51.515348Z",
          "iopub.status.idle": "2024-11-25T17:05:51.526643Z",
          "shell.execute_reply.started": "2024-11-25T17:05:51.515271Z",
          "shell.execute_reply": "2024-11-25T17:05:51.525547Z"
        },
        "id": "fHayReCl60Gi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Initialize the Global Model </b></div>"
      ],
      "metadata": {
        "id": "yGS1JkD460Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the global model\n",
        "global_model = create_model()\n",
        "\n",
        "# Each local model starts with the same initial weights\n",
        "initial_weights = global_model.get_weights()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:05:51.527971Z",
          "iopub.execute_input": "2024-11-25T17:05:51.528319Z",
          "iopub.status.idle": "2024-11-25T17:05:51.590706Z",
          "shell.execute_reply.started": "2024-11-25T17:05:51.528272Z",
          "shell.execute_reply": "2024-11-25T17:05:51.589735Z"
        },
        "id": "s8ALbsqU60Gi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Federated Learning Training</b></div>"
      ],
      "metadata": {
        "id": "mOgS82B660Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of rounds for federated learning\n",
        "num_rounds = 10\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    local_weights = []\n",
        "\n",
        "    # Train on each client\n",
        "    for client_id in range(num_clients):\n",
        "        print(f\"Training on client {client_id + 1}\")\n",
        "\n",
        "        # Create local model and set global weights\n",
        "        local_model = create_model()\n",
        "        local_model.set_weights(global_model.get_weights())\n",
        "\n",
        "        # Get client data\n",
        "        X, y = client_data[client_id]\n",
        "\n",
        "        # Train local model\n",
        "        local_model.fit(X, y, epochs=1, batch_size=32, verbose=0)\n",
        "\n",
        "        # Collect local model weights\n",
        "        local_weights.append(local_model.get_weights())\n",
        "\n",
        "    # Federated averaging: Aggregate local weights\n",
        "    averaged_weights = [np.mean([local_weights[j][i] for j in range(num_clients)], axis=0)\n",
        "                        for i in range(len(local_weights[0]))]\n",
        "\n",
        "    # Update global model weights\n",
        "    global_model.set_weights(averaged_weights)\n",
        "\n",
        "    # Evaluate the global model\n",
        "    loss, accuracy = global_model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Global model accuracy after round {round_num + 1}: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:05:51.591898Z",
          "iopub.execute_input": "2024-11-25T17:05:51.592236Z",
          "iopub.status.idle": "2024-11-25T17:08:12.557565Z",
          "shell.execute_reply.started": "2024-11-25T17:05:51.592203Z",
          "shell.execute_reply": "2024-11-25T17:08:12.556481Z"
        },
        "id": "1Idq2hn160Gi",
        "outputId": "a8bf4aef-40d6-4852-d1a9-d1efe4330a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Round 1/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 1: 0.4043\nRound 2/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 2: 0.5751\nRound 3/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 3: 0.6129\nRound 4/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 4: 0.6457\nRound 5/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 5: 0.6574\nRound 6/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 6: 0.6755\nRound 7/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 7: 0.6855\nRound 8/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 8: 0.6932\nRound 9/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 9: 0.7000\nRound 10/10\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 10: 0.7000\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Define Flower Client</b></div>\n",
        "\n",
        "Flower clients handle local training and evaluation. Each client will train its model using its local data."
      ],
      "metadata": {
        "id": "FxpEFhAw60Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl\n",
        "\n",
        "class CIFARClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, train_data, test_data):\n",
        "        self.model = model\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def get_parameters(self):\n",
        "        # Return model parameters\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        # Set model parameters\n",
        "        self.model.set_weights(parameters)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        x_train, y_train = self.train_data\n",
        "        self.model.fit(x_train, y_train, epochs=1, batch_size=32, verbose=0)\n",
        "        return self.get_parameters(), len(x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        x_test, y_test = self.test_data\n",
        "        loss, accuracy = self.model.evaluate(x_test, y_test, verbose=0)\n",
        "        return float(loss), len(x_test), {\"accuracy\": float(accuracy)}\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:08:12.559363Z",
          "iopub.execute_input": "2024-11-25T17:08:12.560184Z",
          "iopub.status.idle": "2024-11-25T17:08:12.568515Z",
          "shell.execute_reply.started": "2024-11-25T17:08:12.560134Z",
          "shell.execute_reply": "2024-11-25T17:08:12.567308Z"
        },
        "id": "NNl5vBiQ60Gj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Start the Flower Server</b></div>"
      ],
      "metadata": {
        "id": "ZkW6L68O60Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_flower_server():\n",
        "    fl.server.start_server(\n",
        "        server_address=\"0.0.0.0:8080\",\n",
        "        config=fl.server.ServerConfig(num_rounds=3),\n",
        "    )\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:08:12.570116Z",
          "iopub.execute_input": "2024-11-25T17:08:12.570586Z",
          "iopub.status.idle": "2024-11-25T17:08:12.585306Z",
          "shell.execute_reply.started": "2024-11-25T17:08:12.570533Z",
          "shell.execute_reply": "2024-11-25T17:08:12.584332Z"
        },
        "id": "gKjYXrxk60Gj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Start the Flower Client</b></div>"
      ],
      "metadata": {
        "id": "vsi3D9rq60Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_flower_client(client_id):\n",
        "    # Get client-specific data\n",
        "    train_data = client_data[client_id]\n",
        "    test_data = (x_test, y_test)\n",
        "\n",
        "    # Create model\n",
        "    model = create_model()\n",
        "\n",
        "    # Create and start the client\n",
        "    client = CIFARClient(model, train_data, test_data)\n",
        "    fl.client.start_numpy_client(server_address=\"0.0.0.0:8080\", client=client)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:08:12.586613Z",
          "iopub.execute_input": "2024-11-25T17:08:12.586926Z",
          "iopub.status.idle": "2024-11-25T17:08:12.598596Z",
          "shell.execute_reply.started": "2024-11-25T17:08:12.586898Z",
          "shell.execute_reply": "2024-11-25T17:08:12.597649Z"
        },
        "id": "ukt877QU60Gj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Run Federated Learning</b></div>\n",
        "\n",
        "Run the server and clients in parallel. For local testing, you can use threads or separate processes.\n",
        "\n",
        "Run Server"
      ],
      "metadata": {
        "id": "MzAQOz5l60Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl\n",
        "\n",
        "def start_flower_server():\n",
        "    # Define the Federated Averaging strategy\n",
        "    strategy = fl.server.strategy.FedAvg()\n",
        "\n",
        "    # Start the server with the strategy and configuration\n",
        "    fl.server.start_server(\n",
        "        server_address=\"localhost:8087\",\n",
        "        strategy=strategy,\n",
        "        config={\"num_rounds\": 1},\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Start the server directly in the main thread\n",
        "    start_flower_server()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:12:04.261241Z",
          "iopub.execute_input": "2024-11-25T17:12:04.261732Z",
          "iopub.status.idle": "2024-11-25T17:12:04.276644Z",
          "shell.execute_reply.started": "2024-11-25T17:12:04.261694Z",
          "shell.execute_reply": "2024-11-25T17:12:04.274773Z"
        },
        "_kg_hide-output": true,
        "id": "zk4YCeDI60Gj",
        "outputId": "fbdec652-c199-4ff6-e96f-6552914f3b1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n\tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n\n\t\t$ flower-superlink --insecure\n\n\tTo view usage and all available options, run:\n\n\t\t$ flower-superlink --help\n\n\tUsing `start_server()` is deprecated.\n\n            This is a deprecated feature. It will be removed\n            entirely in future versions of Flower.\n        \n\u001b[92mINFO \u001b[0m:      Starting Flower server, config: {'num_rounds': 1}\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Port in server address localhost:8086 is already in use.\n"
          ],
          "ename": "SystemExit",
          "evalue": "Port in server address localhost:8086 is already in use.",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we change the server address from localhost:8086 to 8087, it runs smoothly. Every time it runs, the server address needs to be changed."
      ],
      "metadata": {
        "id": "7ebJjpwn60Gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Run the Flower Client</b></div>"
      ],
      "metadata": {
        "id": "ZNV4FxiV60Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "import flwr as fl\n",
        "\n",
        "def start_flower_client(client_id):\n",
        "    # Replace this with the actual implementation of your client\n",
        "    print(f\"Starting client {client_id}\")\n",
        "    model = create_model()\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    y_train, y_test = tf.keras.utils.to_categorical(y_train, 10), tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    # Create and start the Flower client\n",
        "    client = FlowerClient(model, x_train, y_train, x_test, y_test)\n",
        "    fl.client.start_client(\n",
        "        server_address=\"localhost:8080\",  # Replace with your server address\n",
        "        client=client.to_client(),\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    num_clients = 3  # Adjust the number of clients as needed\n",
        "\n",
        "    # Start clients in separate processes\n",
        "    client_processes = []\n",
        "    for client_id in range(num_clients):\n",
        "        process = Process(target=start_flower_client, args=(client_id,))\n",
        "        client_processes.append(process)\n",
        "        process.start()\n",
        "\n",
        "    # Wait for all clients to finish\n",
        "    for process in client_processes:\n",
        "        process.join()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:12:24.201958Z",
          "iopub.execute_input": "2024-11-25T17:12:24.202387Z",
          "iopub.status.idle": "2024-11-25T17:12:24.873931Z",
          "shell.execute_reply.started": "2024-11-25T17:12:24.202351Z",
          "shell.execute_reply": "2024-11-25T17:12:24.872835Z"
        },
        "id": "yqUDl7ED60Gk",
        "outputId": "c69be09a-f130-49e1-d18d-9e30543734ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Starting client 0\nStarting client 1\nStarting client 2\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2024-11-25 17:12:24.593824: F external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:164] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error\n2024-11-25 17:12:24.596374: F external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:164] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error\n2024-11-25 17:12:24.615518: F external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:164] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Evaluate the Final Global Model</b></div>\n",
        "\n",
        "After federated training is complete, evaluate the final model on the test set:"
      ],
      "metadata": {
        "id": "6ez_gzmQ60Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the final weights from the trained global model\n",
        "global_model_parameters = global_model.get_weights()\n",
        "\n",
        "# Use the final weights to evaluate\n",
        "final_model = create_model()\n",
        "final_model.set_weights(global_model_parameters)\n",
        "loss, accuracy = final_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Final model accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:12:32.275688Z",
          "iopub.execute_input": "2024-11-25T17:12:32.276069Z",
          "iopub.status.idle": "2024-11-25T17:12:33.856053Z",
          "shell.execute_reply.started": "2024-11-25T17:12:32.276038Z",
          "shell.execute_reply": "2024-11-25T17:12:33.854955Z"
        },
        "id": "IDH14Zj760Gk",
        "outputId": "074bff30-31b4-4b93-e91d-baf306f7a4e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Final model accuracy: 0.7000\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b> Final/More Evaluation</b></div>"
      ],
      "metadata": {
        "id": "7zAEnHTO60Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After federated learning rounds\n",
        "num_rounds = 5\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    local_weights = []\n",
        "\n",
        "    # Train on each client\n",
        "    for client_id in range(num_clients):\n",
        "        print(f\"Training on client {client_id + 1}\")\n",
        "\n",
        "        local_model = create_model()\n",
        "        local_model.set_weights(global_model.get_weights())\n",
        "\n",
        "        # Train local model\n",
        "        X, y = client_data[client_id]\n",
        "        local_model.fit(X, y, epochs=1, batch_size=32, verbose=0)\n",
        "\n",
        "        # Collect local weights\n",
        "        local_weights.append(local_model.get_weights())\n",
        "\n",
        "    # Federated averaging\n",
        "    averaged_weights = [np.mean([local_weights[j][i] for j in range(num_clients)], axis=0)\n",
        "                        for i in range(len(local_weights[0]))]\n",
        "    global_model.set_weights(averaged_weights)\n",
        "\n",
        "    # Evaluate global model\n",
        "    loss, accuracy = global_model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Global model accuracy after round {round_num + 1}: {accuracy:.4f}\")\n",
        "\n",
        "# Save final weights\n",
        "global_model_parameters = global_model.get_weights()\n",
        "\n",
        "# Final evaluation\n",
        "final_model = create_model()\n",
        "final_model.set_weights(global_model_parameters)\n",
        "loss, accuracy = final_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Final model accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T17:12:38.559609Z",
          "iopub.execute_input": "2024-11-25T17:12:38.559973Z",
          "iopub.status.idle": "2024-11-25T17:13:53.038199Z",
          "shell.execute_reply.started": "2024-11-25T17:12:38.559941Z",
          "shell.execute_reply": "2024-11-25T17:13:53.036962Z"
        },
        "id": "VZxAr-It60Gk",
        "outputId": "f51a7a6a-870e-4305-ae2e-45b941e8c1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Round 1/5\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 1: 0.7102\nRound 2/5\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 2: 0.7100\nRound 3/5\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 3: 0.7156\nRound 4/5\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 4: 0.7188\nRound 5/5\nTraining on client 1\nTraining on client 2\nTraining on client 3\nGlobal model accuracy after round 5: 0.7161\nFinal model accuracy: 0.7161\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#FF7F50; overflow:hidden\"><b>Conclusion</b></div>"
      ],
      "metadata": {
        "id": "E1oDr8xF60Gk"
      }
    }
  ]
}