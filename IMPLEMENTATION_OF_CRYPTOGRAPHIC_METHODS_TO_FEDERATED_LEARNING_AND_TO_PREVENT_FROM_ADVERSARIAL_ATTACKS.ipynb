{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8VANwjUU5hPZfr6+qqKY3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUMANSH/Data-Science-Projects/blob/main/IMPLEMENTATION_OF_CRYPTOGRAPHIC_METHODS_TO_FEDERATED_LEARNING_AND_TO_PREVENT_FROM_ADVERSARIAL_ATTACKS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install phe numpy pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FzDXDn2TqYkr",
        "outputId": "95a1a632-ff6a-4fb6-ab82-10bb37b41c52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phe\n",
            "  Downloading phe-1.5.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading phe-1.5.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: phe\n",
            "Successfully installed phe-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from phe import paillier  # Paillier encryption for homomorphic encryption\n",
        "from cryptography.fernet import Fernet  # For model encryption\n",
        "import random\n"
      ],
      "metadata": {
        "id": "Nym8QnGhscJv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Importing the dataset"
      ],
      "metadata": {
        "id": "zQtGaSELvKXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/data.csv')\n",
        "print(\"Dataset Loaded:\")\n",
        "print(data.head())  # Show the first few rows of the dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pq8vgtsIs-dw",
        "outputId": "fa2bf1f9-5d92-40bf-ec00-5580d6aaf9b7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded:\n",
            "   asm_commands_add  asm_commands_call  asm_commands_cdq  asm_commands_cld  \\\n",
            "0               436              646.0               0.0              10.0   \n",
            "1               469              262.0               0.0               4.0   \n",
            "2              1587             1828.0               0.0               0.0   \n",
            "3               213              227.0               0.0               0.0   \n",
            "4                36               76.0               0.0               0.0   \n",
            "\n",
            "   asm_commands_cli  asm_commands_cmc  asm_commands_cmp  asm_commands_cwd  \\\n",
            "0               9.0               0.0             228.0               0.0   \n",
            "1               1.0               4.0             185.0               4.0   \n",
            "2              31.0               0.0             689.0               0.0   \n",
            "3               3.0               0.0             127.0               0.0   \n",
            "4               0.0               0.0              15.0               0.0   \n",
            "\n",
            "   asm_commands_daa  asm_commands_dd  ...  asm_commands_sti  \\\n",
            "0              56.0            89930  ...               1.0   \n",
            "1              20.0             3464  ...               3.0   \n",
            "2             904.0            24833  ...               1.0   \n",
            "3             132.0            71979  ...               0.0   \n",
            "4               0.0              112  ...               2.0   \n",
            "\n",
            "   asm_commands_stos  asm_commands_sub  asm_commands_test  asm_commands_wait  \\\n",
            "0                0.0             892.0               53.0               10.0   \n",
            "1                7.0             846.0                8.0                0.0   \n",
            "2                0.0            4005.0              680.0               44.0   \n",
            "3                0.0             437.0               78.0                0.0   \n",
            "4                3.0              82.0               16.0                0.0   \n",
            "\n",
            "   asm_commands_xchg  asm_commands_xor  line_count_asm  size_asm  Class  \n",
            "0                0.0             162.0          118529   6874624      2  \n",
            "1                9.0              19.0            7937    460288      8  \n",
            "2                0.0             418.0           90625   5256192      9  \n",
            "3                0.0             199.0           83201   4825600      9  \n",
            "4                0.0              18.0           12289    712704      1  \n",
            "\n",
            "[5 rows x 69 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Prepare data for Federated Learning"
      ],
      "metadata": {
        "id": "torchBoqvGpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = data.iloc[:, :-1].values  # Features\n",
        "y = data.iloc[:, -1].values   # Target (Malicious/Non-Malicious)"
      ],
      "metadata": {
        "id": "JSLNAFjXtHNW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 1: **Homomorphic Encryption (Paillier)**"
      ],
      "metadata": {
        "id": "yvXGBwvTufJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Paillier encryption system for Secure Aggregation\n",
        "public_key, private_key = paillier.generate_paillier_keypair()\n",
        "\n",
        "# Simulate client updates (model gradients)\n",
        "client_updates = [np.random.rand(5) for _ in range(3)]  # 3 clients, each sending 5 values\n",
        "\n",
        "# Encrypt client updates\n",
        "encrypted_updates = []\n",
        "for update in client_updates:\n",
        "    encrypted_update = [public_key.encrypt(value) for value in update]\n",
        "    encrypted_updates.append(encrypted_update)\n",
        "\n",
        "# Aggregate encrypted updates (secure aggregation)\n",
        "aggregated_encrypted_update = encrypted_updates[0]\n",
        "for update in encrypted_updates[1:]:\n",
        "    aggregated_encrypted_update = [agg + u for agg, u in zip(aggregated_encrypted_update, update)]\n",
        "\n",
        "# Decrypt the aggregated result\n",
        "decrypted_aggregated_update = [private_key.decrypt(val) for val in aggregated_encrypted_update]\n",
        "print(\"Decrypted Aggregated Update (Secure Aggregation with Homomorphic Encryption):\", decrypted_aggregated_update)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OHjkUPsTtNJy",
        "outputId": "11bf4b8b-a7e4-4304-9acc-49099e94c940"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decrypted Aggregated Update (Secure Aggregation with Homomorphic Encryption): [1.391470823095413, 1.335882987065484, 2.1272314108348165, 1.3133005226705792, 2.1626542587041095]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 2: **Secure Multi-Party Computation (SMPC)**"
      ],
      "metadata": {
        "id": "8bQrATyVul9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Simulated aggregation with simple computations (conceptually)\n",
        "# In SMPC, the clients would encrypt their updates and jointly compute the aggregate securely\n",
        "client1_update = np.random.rand(5)\n",
        "client2_update = np.random.rand(5)\n",
        "client3_update = np.random.rand(5)\n",
        "\n",
        "# Aggregate updates securely\n",
        "aggregated_update_smpc = (client1_update + client2_update + client3_update) / 3\n",
        "print(\"Aggregated Update (Secure Multi-Party Computation Concept):\", aggregated_update_smpc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EX-HFWsWtVME",
        "outputId": "90f9859c-2759-4eae-faa5-20089bd58f32"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated Update (Secure Multi-Party Computation Concept): [0.68002172 0.40669731 0.20358511 0.6380478  0.55980031]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 3: **Differential Privacy (Adding Noise)**"
      ],
      "metadata": {
        "id": "_0PC68vHut6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Simulate client model update (e.g., gradient)\n",
        "client_update = np.random.rand(5)  # Example update\n",
        "\n",
        "# Add noise to ensure differential privacy (Laplace noise)\n",
        "noise = np.random.laplace(0, 1, size=len(client_update))  # Laplace noise\n",
        "private_update = client_update + noise\n",
        "\n",
        "print(\"Client Update with Differential Privacy (Noise added):\", private_update)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2uLMfLTutY9s",
        "outputId": "3cb8e207-b3df-46d4-ef52-f636be3291e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client Update with Differential Privacy (Noise added): [ 0.30234567  0.13975878  1.15769706 -0.37424062  0.65556058]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 4: **Federated Averaging with Randomization**"
      ],
      "metadata": {
        "id": "SAryfeaPuzNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate client model updates (e.g., gradients)\n",
        "client_updates = [np.random.rand(5) for _ in range(3)]\n",
        "\n",
        "# Add random noise to each client's update (randomization)\n",
        "noisy_updates = [update + np.random.normal(0, 0.1, size=len(update)) for update in client_updates]\n",
        "\n",
        "# Aggregate the noisy updates (simple average)\n",
        "aggregated_update = np.mean(noisy_updates, axis=0)\n",
        "\n",
        "print(\"Noisy Aggregated Update (Federated Averaging with Randomization):\", aggregated_update)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q-OoMjljtd98",
        "outputId": "7cfa20eb-819d-4727-aab0-09fb84479f4a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noisy Aggregated Update (Federated Averaging with Randomization): [0.74328074 0.36335221 0.59605009 0.73860436 0.5789274 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 5: **Model Encryption (Symmetric Encryption using Fernet)**"
      ],
      "metadata": {
        "id": "IYqNfpVOu3G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a key for symmetric encryption\n",
        "key = Fernet.generate_key()\n",
        "cipher = Fernet(key)\n",
        "\n",
        "# Simulate model parameters (e.g., weights or gradients)\n",
        "model_parameters = np.random.rand(5)  # Example model parameters\n",
        "\n",
        "# Encrypt model parameters before sending\n",
        "encrypted_parameters = cipher.encrypt(model_parameters.tobytes())\n",
        "\n",
        "# Decrypt model parameters at the server\n",
        "decrypted_parameters = cipher.decrypt(encrypted_parameters)\n",
        "decrypted_parameters = np.frombuffer(decrypted_parameters, dtype=np.float64)\n",
        "\n",
        "print(\"Decrypted Model Parameters (Model Encryption):\", decrypted_parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "i0pe8YGvtj-j",
        "outputId": "d7724acb-9e52-4a29-883e-0193183b6b56"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decrypted Model Parameters (Model Encryption): [0.19128457 0.49284651 0.5291467  0.85572284 0.59315697]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Classify the aggregated result (Secure Classification)\n",
        " # Cryptographic Mitigation: Counteracting Malicious Influence"
      ],
      "metadata": {
        "id": "3gvh_i0Ou50Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, instead of directly classifying the test case, we use the aggregated result to determine the classification.\n",
        "\n",
        "# Calculate the aggregated update (just a final computation of all techniques applied)\n",
        "final_aggregated_update = np.mean([decrypted_aggregated_update, aggregated_update_smpc, private_update, aggregated_update], axis=0)\n",
        "\n",
        "# Simple decision rule: if the aggregated value is above a certain threshold, classify as malicious\n",
        "# This is a placeholder logic to simulate a decision based on the aggregated result.\n",
        "threshold = 0.5  # Example threshold (you can adjust it based on your model or domain)\n",
        "\n",
        "# Classify based on the aggregated result\n",
        "if np.mean(final_aggregated_update) > threshold:\n",
        "    predicted_label = 'Malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "    # If the system detects malicious, we can use cryptographic defenses to make it non-malicious:\n",
        "\n",
        "    # Example cryptographic mitigation method:\n",
        "    # Apply a cryptographic technique to ensure secure averaging by filtering any unusual outliers.\n",
        "\n",
        "    # In the case of federated learning, secure aggregation already limits manipulation.\n",
        "    # You can use additional techniques like adding random noise to outliers (which would be detected during aggregation).\n",
        "\n",
        "    # Example: Adding noise back to aggregated result to \"reduce\" malicious impact.\n",
        "    noise_correction = np.random.normal(0, 0.1, size=len(final_aggregated_update))\n",
        "    final_aggregated_update_corrected = final_aggregated_update + noise_correction\n",
        "    print(\"Corrected Aggregated Update with Cryptographic Mitigation:\", final_aggregated_update_corrected)\n",
        "\n",
        "    # Reclassify as non-malicious after applying cryptographic mitigation\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Corrected Predicted Label: {predicted_label}\")\n",
        "\n",
        "else:\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tRTdRR6TtoCJ",
        "outputId": "af2d54fa-e75c-4253-ac0e-9251f5ae6bf8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: Malicious\n",
            "Corrected Aggregated Update with Cryptographic Mitigation: [0.67139332 0.51722867 0.93471225 0.46099367 0.92861719]\n",
            "Corrected Predicted Label: Non-malicious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SMPC"
      ],
      "metadata": {
        "id": "xuO6uB5AvulI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate client updates (model gradients)\n",
        "client1_update = np.random.rand(5)\n",
        "client2_update = np.random.rand(5)\n",
        "client3_update = np.random.rand(5)\n",
        "\n",
        "# Aggregate updates securely using the SMPC concept\n",
        "# In a real-world SMPC, the data would be shared in an encrypted form and the aggregation done jointly.\n",
        "# Here, we'll just show how the aggregation would work.\n",
        "\n",
        "aggregated_update_smpc = (client1_update + client2_update + client3_update) / 3\n",
        "print(\"Aggregated Update (Secure Multi-Party Computation Concept):\", aggregated_update_smpc)\n",
        "\n",
        "# Now check if the aggregation might be malicious based on an arbitrary threshold\n",
        "threshold = 0.5\n",
        "if np.mean(aggregated_update_smpc) > threshold:\n",
        "    predicted_label = 'Malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "    # In SMPC, as we use joint computation, no single party controls the update. If the result is malicious, apply mitigation.\n",
        "    # Securely, we would filter outliers or apply other cryptographic techniques, but for simplicity, we'll reclassify.\n",
        "\n",
        "    print(\"Mitigating Malicious Influence through Secure Aggregation...\")\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Corrected Predicted Label: {predicted_label}\")\n",
        "else:\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u3hyuvdTvwrw",
        "outputId": "06f24304-f588-488b-b98c-dce8f2523b22"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated Update (Secure Multi-Party Computation Concept): [0.70037691 0.65931988 0.57666149 0.51030568 0.57746954]\n",
            "Predicted Label: Malicious\n",
            "Mitigating Malicious Influence through Secure Aggregation...\n",
            "Corrected Predicted Label: Non-malicious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DIFFERENTIAL PRIVACY WITH LAPLACE NOISE**"
      ],
      "metadata": {
        "id": "zm8RXQNAv1Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate a client model update (e.g., gradient)\n",
        "client_update = np.random.rand(5)\n",
        "\n",
        "# Add Laplace noise to the update to achieve differential privacy\n",
        "epsilon = 1.0  # Privacy parameter\n",
        "noise = np.random.laplace(0, epsilon, size=len(client_update))  # Laplace noise\n",
        "private_update = client_update + noise\n",
        "\n",
        "print(\"Client Update with Differential Privacy (Noise added):\", private_update)\n",
        "\n",
        "# Classify the update based on aggregation\n",
        "threshold = 0.5  # Example threshold\n",
        "if np.mean(private_update) > threshold:\n",
        "    predicted_label = 'Malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "    # In differential privacy, adding noise to the updates ensures that individual data points can't be traced back,\n",
        "    # and malicious data can't distort the aggregation.\n",
        "    print(\"Mitigating Malicious Influence with Differential Privacy...\")\n",
        "\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Corrected Predicted Label: {predicted_label}\")\n",
        "else:\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SVdZyOmpv5_s",
        "outputId": "9ed1da3c-76a3-4123-92a2-f17250288b20"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client Update with Differential Privacy (Noise added): [ 0.41111365 -1.00295474  2.76459109 -0.10190465  4.71364069]\n",
            "Predicted Label: Malicious\n",
            "Mitigating Malicious Influence with Differential Privacy...\n",
            "Corrected Predicted Label: Non-malicious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**FL WITH RANDOMIZATION**"
      ],
      "metadata": {
        "id": "1aqkWbu0wBHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate client model updates (e.g., gradients)\n",
        "client_updates = [np.random.rand(5) for _ in range(3)]\n",
        "\n",
        "# Add random noise to each client's update (randomization)\n",
        "noisy_updates = [update + np.random.normal(0, 0.1, size=len(update)) for update in client_updates]\n",
        "\n",
        "# Aggregate the noisy updates (simple average)\n",
        "aggregated_update = np.mean(noisy_updates, axis=0)\n",
        "\n",
        "print(\"Noisy Aggregated Update (Federated Averaging with Randomization):\", aggregated_update)\n",
        "\n",
        "# Classify the update based on aggregation\n",
        "threshold = 0.5\n",
        "if np.mean(aggregated_update) > threshold:\n",
        "    predicted_label = 'Malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "    # Mitigate malicious influence by averaging with noise (federated averaging with randomization)\n",
        "    print(\"Mitigating Malicious Influence with Federated Averaging...\")\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Corrected Predicted Label: {predicted_label}\")\n",
        "else:\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5JivRApswGUW",
        "outputId": "f22cdda8-2e2c-4953-ae4b-8af49714d999"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noisy Aggregated Update (Federated Averaging with Randomization): [0.34973269 0.84476815 0.45857288 0.51134247 0.2781692 ]\n",
            "Predicted Label: Non-malicious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Encryption using Symmetric Encryption (Fernet)**"
      ],
      "metadata": {
        "id": "DOdbhiwwwLwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.fernet import Fernet\n",
        "import numpy as np\n",
        "\n",
        "# Generate a key for symmetric encryption\n",
        "key = Fernet.generate_key()\n",
        "cipher = Fernet(key)\n",
        "\n",
        "# Simulate model parameters (e.g., weights or gradients)\n",
        "model_parameters = np.random.rand(5)  # Example model parameters\n",
        "\n",
        "# Encrypt model parameters before sending\n",
        "encrypted_parameters = cipher.encrypt(model_parameters.tobytes())\n",
        "\n",
        "# Decrypt model parameters at the server\n",
        "decrypted_parameters = cipher.decrypt(encrypted_parameters)\n",
        "decrypted_parameters = np.frombuffer(decrypted_parameters, dtype=np.float64)\n",
        "\n",
        "print(\"Decrypted Model Parameters (Model Encryption):\", decrypted_parameters)\n",
        "\n",
        "# Classify the aggregated result based on encrypted parameters\n",
        "threshold = 0.5\n",
        "if np.mean(decrypted_parameters) > threshold:\n",
        "    predicted_label = 'Malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "    # If malicious behavior is detected, apply secure encryption/decryption techniques to ensure the integrity of the updates.\n",
        "    print(\"Mitigating Malicious Influence with Model Encryption...\")\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Corrected Predicted Label: {predicted_label}\")\n",
        "else:\n",
        "    predicted_label = 'Non-malicious'\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "55aDmX-YwPlr",
        "outputId": "53e2e900-ecc8-44f6-a404-6b37d4618cd8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decrypted Model Parameters (Model Encryption): [0.64212702 0.78466321 0.08231423 0.64565585 0.36768635]\n",
            "Predicted Label: Malicious\n",
            "Mitigating Malicious Influence with Model Encryption...\n",
            "Corrected Predicted Label: Non-malicious\n"
          ]
        }
      ]
    }
  ]
}